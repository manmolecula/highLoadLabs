# BigDataSnowflake
**Лабораторная работа №1: Нормализация данных в модель «снежинка» для анализа больших данных**

---

## Описание задачи

Одной из ключевых задач data engineer при работе с данными BigData является трансформация исходной модели данных источника в аналитическую модель, которая позволяет эффективно исследовать данные и принимать обоснованные решения. Классическими универсальными схемами для аналитической обработки данных являются модели **«звезда»** и **«снежинка»**. В данной лабораторной работе вам предстоит освоить навыки трансформации исходных данных из различных источников в нормализованную модель данных «снежинка».

Необходимо выполнить нормализацию исходных данных (файлы `mock_data.csv` с номерами), содержащих информацию о покупателях, продавцах, поставщиках, магазинах и товарах для домашних питомцев, и преобразовать их в модель «снежинка» или «звезда». Модель должна включать таблицы фактов и нормализованные таблицы измерений.

![Лабораторная работа №1](https://github.com/user-attachments/assets/5bdd26dc-b9e5-4ddc-8df4-456d25503af4)

Алгоритм:
1. Клонируете к себе этот репозиторий.
2. Устанавливаете себе инструмент для работы с запросами SQL (рекомендую DBeaver).
3. Запускаете базу данных PostgreSQL (рекомендую установку через docker).
4. Скачиваете файлы с исходными данными mock_data( * ).csv, где ( * ) номера файлов. Всего 10 файлов, каждый по 1000 строк.
5. Импортируете данные в БД PostgreSQL (например, через механизм импорта csv в DBeaver). Всего в таблице mock_data должно находиться 10000 строк из 10 файлов.
6. Анализируете исходные данные с помощью запросов.
7. Выявляете сущности фактов и измерений.
8. Реализуете скрипты DDL для создания таблиц фактов и измерений.
9. Реализуете скрипты DML для заполнения таблиц фактов и измерений из исходных данных.
10. Проверяете полученный результат.
11. Отправляете результат на проверку лаборантам.
12. Обсуждаете работу с лаборантами.

Что должно быть результатом работы?v
1. Репозиторий, в котором есть исходные данные mock_data( * ).csv, где ( * ) номера файлов. Всего 10 файлов, каждый по 1000 строк.
2. Файл docker-compose.yml с установкой PostgreSQL и заполненными данными из файлов mock_data(*).csv.
3. Скрипты DDL (SQL) создания таблиц фактов и измерений в соответствии с моделью снежинка/звезда.
4. Скрипты DML (SQL) заполнения таблиц фактов и измерений из исходных данных.
